{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "795038d1",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1efc85a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.backends import cudnn\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torchvision import models\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "\n",
    "from skimage import io, transform\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e4b79b",
   "metadata": {},
   "source": [
    "# Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3e5d8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_ADD = 'train_add.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd695831",
   "metadata": {},
   "source": [
    "# ِDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fabf473",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceForensic():\n",
    "    \"\"\"Face Forensic Dataset.\"\"\"\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.face_add = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.face_add)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_add = self.face_add.iloc[idx, 1]\n",
    "        image = Image.open(img_add)\n",
    "        if self.transform:\n",
    "            if idx % 4 in [0,2]: \n",
    "                image = self.transform['transform1'](image)\n",
    "            #elif idx % 4 == 1:\n",
    "                #image = self.transform['transform2'](image)\n",
    "            else:\n",
    "                image = self.transform['transform2'](image)\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328cb1a3",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db60f440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize input\n",
    "inp_size = (224,224)\n",
    "\n",
    "# Normalize inputs\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Gaussian blur input\n",
    "kernel_size = (5, 9)\n",
    "sigma = (0.1, 5)\n",
    "\n",
    "# Probablity of verflip or horflip\n",
    "p_verflip = 0.5\n",
    "p_horflip = 0.5\n",
    "\n",
    "\n",
    "transform1 = transforms.Compose([transforms.Resize(inp_size), transforms.ToTensor(),\n",
    "                                  transforms.Normalize(mean, std)])\n",
    "\n",
    "transform2 = transforms.Compose([transforms.RandomVerticalFlip(p=p_verflip),transforms.RandomHorizontalFlip(p=p_horflip),\n",
    "                                 transforms.GaussianBlur(kernel_size=kernel_size, sigma=sigma),\n",
    "                                 transforms.Resize(inp_size),transforms.ToTensor(),\n",
    "                                 transforms.Normalize(mean, std)])\n",
    "\n",
    "trasnform3 = transforms.Compose([transforms.RandomHorizontalFlip(p=1),transforms.Resize(inp_size),transforms.ToTensor(),\n",
    "                  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "trfms = {'transform1': transform1 ,'transform2': transform2}\n",
    "#forensic_dataset = FaceForensic('train_add.csv', trfms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143a3219",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "203058c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_contrastive_loader(dataset, transforms, csv_add, batch_size=128, shuffle=False):\n",
    "    \"\"\"Return data loaders\"\"\"\n",
    "    \n",
    "    forensic_dataset = dataset(csv_add, transforms)\n",
    "    \n",
    "    dataloader = DataLoader(forensic_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382daeef",
   "metadata": {},
   "source": [
    "# Contrastive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd9256ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConEfficient(nn.Module):\n",
    "    \"\"\"backbone + projection head\"\"\"\n",
    "    \n",
    "    def __init__(self, name='Efficient-B0', pretrained=True, head='mlp', dim_in=1280, feat_dim=128):\n",
    "        \n",
    "        super(ConEfficient, self).__init__()\n",
    "        efficientnet = models.efficientnet_b0(pretrained=pretrained)\n",
    "        return_nodes = {\"avgpool\": \"represent\"}\n",
    "        self.encoder = create_feature_extractor(efficientnet, return_nodes=return_nodes)\n",
    "        self.dim_in = dim_in\n",
    "        if head == 'linear':\n",
    "            self.head = nn.Linear(dim_in, feat_dim)\n",
    "        elif head == 'mlp':\n",
    "            self.head = nn.Sequential(\n",
    "                nn.Linear(dim_in, dim_in),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(dim_in, feat_dim)\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError(\n",
    "                'head not supported: {}'.format(head))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        feat = self.encoder(x)['represent'].view(-1,self.dim_in)\n",
    "        feat = F.normalize(self.head(feat), dim=1)\n",
    "        return feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784fe1fd",
   "metadata": {},
   "source": [
    "# Adjust Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11ee55f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, mode, args):\n",
    "    \"\"\"\n",
    "    :param optimizer: torch.optim\n",
    "    :param epoch: int\n",
    "    :param mode: str\n",
    "    :param args: argparse.Namespace\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if mode == \"contrastive\":\n",
    "        lr = args['lr_contrastive']\n",
    "        n_epochs = args['n_epochs_contrastive']\n",
    "    elif mode == \"cross_entropy\":\n",
    "        lr = args['lr_cross_entropy']\n",
    "        n_epochs = args['n_epochs_cross_entropy']\n",
    "    else:\n",
    "        raise ValueError(\"Mode {} unknown\".format(mode))\n",
    "\n",
    "    if args['cosine']:\n",
    "        eta_min = lr * (args['lr_decay_rate'] ** 3)\n",
    "        lr = eta_min + (lr - eta_min) * (1 + math.cos(math.pi * epoch / n_epochs)) / 2\n",
    "    else:\n",
    "        n_steps_passed = np.sum(epoch > np.asarray(args['lr_decay_epochs']))\n",
    "                                \n",
    "        if n_steps_passed > 0:\n",
    "                lr = lr * (args['lr_decay_rate'] ** n_steps_passed)\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dce0b3",
   "metadata": {},
   "source": [
    "# Contrastive Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0dcba9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConLoss(nn.Module):\n",
    "    \"\"\"Supervised Contrastive Learning: https://arxiv.org/pdf/2004.11362.pdf.\n",
    "    It also supports the unsupervised contrastive loss in SimCLR\"\"\"\n",
    "    def __init__(self, temperature=0.07, contrast_mode='all',\n",
    "                 base_temperature=0.07, device=\"cpu\"):\n",
    "        super(ConLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.contrast_mode = contrast_mode\n",
    "        self.base_temperature = base_temperature\n",
    "        self.device = device\n",
    "    \n",
    "    def calc_loss(self, sim_mat):\n",
    "        \n",
    "        \"\"\"Calculate Loss for every four images\"\"\"\n",
    "        \n",
    "        mask_1 = torch.Tensor([[0,1,0,0],[1,0,0,0],[0,0,0,1],[0,0,1,0]])\n",
    "        mask_1 = mask_1.to(self.device)\n",
    "        mask_2 = torch.ones((4,4)) - torch.eye(4)\n",
    "        mask_2 = mask_2.to(self.device)\n",
    "        \n",
    "        sim_mat_num = sim_mat * mask_1\n",
    "        sim_mat_denum = torch.exp(sim_mat) * mask_2\n",
    "        \n",
    "        num = sim_mat_num.sum(1, keepdim=True)\n",
    "        denum = torch.log(sim_mat_denum.sum(1, keepdim=True))\n",
    "        \n",
    "        loss = -1 * (num - denum)\n",
    "        return loss.sum()\n",
    "    \n",
    "    def forward(self, features, labels=None, mask=None):\n",
    "\n",
    "        \"\"\"Compute loss for model. If both `labels` and `mask` are None,\n",
    "        it degenerates to SimCLR unsupervised loss:\n",
    "        https://arxiv.org/pdf/2002.05709.pdf\n",
    "        Args:\n",
    "            features: hidden vector of shape [bsz, n_views, ...].\n",
    "            labels: ground truth of shape [bsz].\n",
    "            mask: contrastive mask of shape [bsz, bsz], mask_{i,j}=1 if sample j\n",
    "                has the same class as sample i. Can be asymmetric.\n",
    "        Returns:\n",
    "            A loss scalar.\n",
    "        \"\"\"\n",
    "        \n",
    "        features = features.view(-1,4,features.size()[1])\n",
    "        features_trp = torch.transpose(features, 1, 2)\n",
    "        # compute logits\n",
    "        anchor_dot_contrast = torch.div(\n",
    "            torch.matmul(features, features_trp),\n",
    "            self.temperature)\n",
    "        #print(anchor_dot_contrast.size())\n",
    "        #print(anchor_dot_contrast)\n",
    "        # for numerical stability\n",
    "        total_loss = 0\n",
    "        for idx in range(features.size()[0]):\n",
    "            loss = self.calc_loss(anchor_dot_contrast)\n",
    "            total_loss += loss\n",
    "        \n",
    "        avg_loss = loss / (features.size()[0] * features.size()[1]) \n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb86b9c",
   "metadata": {},
   "source": [
    "# Train Contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3641483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_contrastive(model, train_loader, criterion, optimizer, writer, args):\n",
    "    \"\"\"\n",
    "    :param model: torch.nn.Module Model\n",
    "    :param train_loader: torch.utils.data.DataLoader\n",
    "    :param criterion: torch.nn.Module Loss\n",
    "    :param optimizer: torch.optim\n",
    "    :param writer: torch.utils.tensorboard.SummaryWriter\n",
    "    :param args: argparse.Namespace\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    best_loss = float(\"inf\")\n",
    "    \n",
    "    for epoch in range(args['n_epochs_contrastive']):\n",
    "        print(\"Epoch [{}/{}]\".format(epoch + 1, args['n_epochs_contrastive']))\n",
    "        train_loss = 0\n",
    "        \n",
    "        for batch_idx, (inputs) in enumerate(train_loader):\n",
    "            \n",
    "            inputs = inputs.to(args['device'])\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            projections = model(inputs)\n",
    "            loss = criterion(projections)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            writer.add_scalar(\n",
    "                \"Loss train | Supervised Contrastive\",\n",
    "                loss.item(),\n",
    "                epoch * len(train_loader) + batch_idx,\n",
    "            )\n",
    "            progress_bar(\n",
    "                batch_idx,\n",
    "                len(train_loader),\n",
    "                \"Loss: {:.3f} \".format(train_loss / (batch_idx + 1)),\n",
    "            )\n",
    "            \n",
    "            avg_loss = train_loss / (batch_idx + 1)\n",
    "        \n",
    "        # Only check every 10 epochs otherwise you will always save\n",
    "        if epoch % 10 == 0:\n",
    "            if (train_loss / (batch_idx + 1)) < best_loss:\n",
    "                print(\"Saving..\")\n",
    "                state = {\n",
    "                    \"net\": model.state_dict(),\n",
    "                    \"avg_loss\": avg_loss,\n",
    "                    \"epoch\": epoch,\n",
    "                }\n",
    "                if not os.path.isdir(\"checkpoint\"):\n",
    "                    os.mkdir(\"checkpoint\")\n",
    "                torch.save(state, \"./checkpoint/ckpt_contrastive.pth\")\n",
    "                best_loss = avg_loss\n",
    "                \n",
    "        adjust_learning_rate(optimizer, epoch, mode=\"contrastive\", args=args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15ec666",
   "metadata": {},
   "source": [
    "# Train Crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f21fc195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cross_entropy(model, train_loader, test_loader, criterion, optimizer, writer, args):\n",
    "    \"\"\"\n",
    "    :param model: torch.nn.Module Model\n",
    "    :param train_loader: torch.utils.data.DataLoader\n",
    "    :param test_loader: torch.utils.data.DataLoader\n",
    "    :param criterion: torch.nn.Module Loss\n",
    "    :param optimizer: torch.optim\n",
    "    :param writer: torch.utils.tensorboard.SummaryWriter\n",
    "    :param args: argparse.Namespace\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    for epoch in range(args['n_epochs_cross_entropy']):  # loop over the dataset multiple times\n",
    "        print(\"Epoch [{}/{}]\".format(epoch + 1, args['n_epochs_cross_entropy']))\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.to(args['device']), targets.to(args['device'])\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "\n",
    "            total_batch = targets.size(0)\n",
    "            correct_batch = predicted.eq(targets).sum().item()\n",
    "            total += total_batch\n",
    "            correct += correct_batch\n",
    "\n",
    "            writer.add_scalar(\n",
    "                \"Loss train | Cross Entropy\",\n",
    "                loss.item(),\n",
    "                epoch * len(train_loader) + batch_idx,\n",
    "            )\n",
    "            writer.add_scalar(\n",
    "                \"Accuracy train | Cross Entropy\",\n",
    "                correct_batch / total_batch,\n",
    "                epoch * len(train_loader) + batch_idx,\n",
    "            )\n",
    "            progress_bar(\n",
    "                batch_idx,\n",
    "                len(train_loader),\n",
    "                \"Loss: {:.3f} | Acc: {:.3f}%% ({}/{})\".format(\n",
    "                    train_loss / (batch_idx + 1),\n",
    "                    100.0 * correct / total,\n",
    "                    correct,\n",
    "                    total,\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        validation(epoch, model, test_loader, criterion, writer, args)\n",
    "\n",
    "        adjust_learning_rate(optimizer, epoch, mode='cross_entropy', args=args)\n",
    "              \n",
    "    print(\"Finished Training\")\n",
    "              \n",
    "              \n",
    "def validation(epoch, model, test_loader, criterion, writer, args):\n",
    "    \"\"\"\n",
    "    :param epoch: int\n",
    "    :param model: torch.nn.Module, Model\n",
    "    :param test_loader: torch.utils.data.DataLoader\n",
    "    :param criterion: torch.nn.Module, Loss\n",
    "    :param writer: torch.utils.tensorboard.SummaryWriter\n",
    "    :param args: argparse.Namespace\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(args['device']), targets.to(args['device'])\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            progress_bar(\n",
    "                batch_idx,\n",
    "                len(test_loader),\n",
    "                \"Loss: {:.3f} | Acc: {:.3f}%% ({}/{})\".format(\n",
    "                    test_loss / (batch_idx + 1),\n",
    "                    100.0 * correct / total,\n",
    "                    correct,\n",
    "                    total,\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.0 * correct / total\n",
    "    writer.add_scalar(\"Accuracy validation | Cross Entropy\", acc, epoch)\n",
    "\n",
    "    if acc > args.best_acc:\n",
    "        print(\"Saving..\")\n",
    "        state = {\n",
    "            \"net\": model.state_dict(),\n",
    "            \"acc\": acc,\n",
    "            \"epoch\": epoch,\n",
    "        }\n",
    "        if not os.path.isdir(\"checkpoint\"):\n",
    "            os.mkdir(\"checkpoint\")\n",
    "        torch.save(state, \"./checkpoint/ckpt_cross_entropy.pth\")\n",
    "        args.best_acc = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f380109",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ad76e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "_, term_width = shutil.get_terminal_size()\n",
    "term_width = int(term_width)\n",
    "\n",
    "TOTAL_BAR_LENGTH = 65.\n",
    "last_time = time.time()\n",
    "begin_time = last_time\n",
    "\n",
    "\n",
    "def progress_bar(current, total, msg=None):\n",
    "    global last_time, begin_time\n",
    "    if current == 0:\n",
    "        begin_time = time.time()  # Reset for new bar.\n",
    "\n",
    "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
    "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
    "\n",
    "    sys.stdout.write(' [')\n",
    "    for i in range(cur_len):\n",
    "        sys.stdout.write('=')\n",
    "    sys.stdout.write('>')\n",
    "    for i in range(rest_len):\n",
    "        sys.stdout.write('.')\n",
    "    sys.stdout.write(']')\n",
    "\n",
    "    cur_time = time.time()\n",
    "    step_time = cur_time - last_time\n",
    "    last_time = cur_time\n",
    "    tot_time = cur_time - begin_time\n",
    "\n",
    "    L = []\n",
    "    L.append('  Step: %s' % format_time(step_time))\n",
    "    L.append(' | Tot: %s' % format_time(tot_time))\n",
    "    if msg:\n",
    "        L.append(' | ' + msg)\n",
    "\n",
    "    msg = ''.join(L)\n",
    "    sys.stdout.write(msg)\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
    "        sys.stdout.write(' ')\n",
    "\n",
    "    # Go back to the center of the bar.\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
    "        sys.stdout.write('\\b')\n",
    "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
    "\n",
    "    if current < total-1:\n",
    "        sys.stdout.write('\\r')\n",
    "    else:\n",
    "        sys.stdout.write('\\n')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def format_time(seconds):\n",
    "    days = int(seconds / 3600/24)\n",
    "    seconds = seconds - days*3600*24\n",
    "    hours = int(seconds / 3600)\n",
    "    seconds = seconds - hours*3600\n",
    "    minutes = int(seconds / 60)\n",
    "    seconds = seconds - minutes*60\n",
    "    secondsf = int(seconds)\n",
    "    seconds = seconds - secondsf\n",
    "    millis = int(seconds*1000)\n",
    "\n",
    "    f = ''\n",
    "    i = 1\n",
    "    if days > 0:\n",
    "        f += str(days) + 'D'\n",
    "        i += 1\n",
    "    if hours > 0 and i <= 2:\n",
    "        f += str(hours) + 'h'\n",
    "        i += 1\n",
    "    if minutes > 0 and i <= 2:\n",
    "        f += str(minutes) + 'm'\n",
    "        i += 1\n",
    "    if secondsf > 0 and i <= 2:\n",
    "        f += str(secondsf) + 's'\n",
    "        i += 1\n",
    "    if millis > 0 and i <= 2:\n",
    "        f += str(millis) + 'ms'\n",
    "        i += 1\n",
    "    if f == '':\n",
    "        f = '0ms'\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1f8f683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "\n",
    "    '''\n",
    "    train_set = None\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set,\n",
    "        batch_size = args['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=args['num_workers']\n",
    "    )\n",
    "    \n",
    "    test_set = None\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_set,\n",
    "        batch_size=args['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=argss['num_workers']\n",
    "    )\n",
    "    '''\n",
    "    # Cotrastive Model\n",
    "    \n",
    "    model = ConEfficient()\n",
    "    model = model.to(args['device'])\n",
    "    \n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "    if not os.path.isdir(\"logs\"):\n",
    "        os.mkdir(\"logs\")\n",
    "        \n",
    "    writer = SummaryWriter(\"logs\")\n",
    "    \n",
    "    if args['training_mode'] == 'contrastive':\n",
    "        train_loader_contrastive = set_contrastive_loader(FaceForensic, trfms, CSV_ADD, \n",
    "                                                          batch_size=args['batch_size'], shuffle=False)\n",
    "        \n",
    "        # define optimizer\n",
    "        optimizer = optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=args['lr_contrastive'],\n",
    "            momentum=args['momentum'],\n",
    "            weight_decay=args['weight_decay'],\n",
    "        )  \n",
    "        \n",
    "        criterion = ConLoss(device=args['device'])\n",
    "        criterion.to(args['device'])\n",
    "        train_contrastive(model, train_loader_contrastive, criterion, optimizer, writer, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf3b1737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Master\\MasterProject\\Codes\\DeepFakeContrastiveLearning\\DeepFake-Detection-Contrastive-Learning\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "E:\\Master\\MasterProject\\Codes\\DeepFakeContrastiveLearning\\DeepFake-Detection-Contrastive-Learning\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500]\n",
      " [===========================================>.....................]  Step: 2s182ms | Tot: 4s484ms | Loss: 4.656  3/3 \n",
      "Saving..\n",
      "Epoch [2/500]\n",
      " [===========================================>.....................]  Step: 2s140ms | Tot: 4s295ms | Loss: 4.394  3/3 \n",
      "Epoch [3/500]\n",
      " [===========================================>.....................]  Step: 2s183ms | Tot: 4s381ms | Loss: 4.425  3/3 \n",
      "Epoch [4/500]\n",
      " [===========================================>.....................]  Step: 2s175ms | Tot: 4s307ms | Loss: 4.393  3/3 \n",
      "Epoch [5/500]\n",
      " [===========================================>.....................]  Step: 2s138ms | Tot: 4s249ms | Loss: 4.407  3/3 \n",
      "Epoch [6/500]\n",
      " [===========================================>.....................]  Step: 2s743ms | Tot: 4s881ms | Loss: 4.390  3/3 \n",
      "Epoch [7/500]\n",
      " [===========================================>.....................]  Step: 2s669ms | Tot: 4s758ms | Loss: 4.360  3/3 \n",
      "Epoch [8/500]\n",
      " [===========================================>.....................]  Step: 2s124ms | Tot: 4s498ms | Loss: 4.532  3/3 \n",
      "Epoch [9/500]\n",
      " [=====================>...........................................]  Step: 1s997ms | Tot: 1s998ms | Loss: 4.394  2/3 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [34], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m device\n\u001b[1;32m---> 10\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [24], line 46\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     44\u001b[0m criterion \u001b[38;5;241m=\u001b[39m ConLoss(device\u001b[38;5;241m=\u001b[39margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     45\u001b[0m criterion\u001b[38;5;241m.\u001b[39mto(args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 46\u001b[0m \u001b[43mtrain_contrastive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_contrastive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [28], line 25\u001b[0m, in \u001b[0;36mtrain_contrastive\u001b[1;34m(model, train_loader, criterion, optimizer, writer, args)\u001b[0m\n\u001b[0;32m     23\u001b[0m projections \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(projections)\n\u001b[1;32m---> 25\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     28\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mE:\\Master\\MasterProject\\Codes\\DeepFakeContrastiveLearning\\DeepFake-Detection-Contrastive-Learning\\venv\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Master\\MasterProject\\Codes\\DeepFakeContrastiveLearning\\DeepFake-Detection-Contrastive-Learning\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args = {'training_mode': 'contrastive', 'batch_size': 4, \n",
    "        'num_workers': 1,'temprature': 0.07,'cosine': True,\n",
    "        'n_epochs_contrastive': 500, 'lr_contrastive': 1e-1, \n",
    "        'n_epochs_cross_entropy': 100, 'lr_cross_entropy': 5e-2,\n",
    "        'momentum': 0.9, 'lr_decay_rate': 0.1,'lr_decay_epochs': [150, 300, 500],'weight_decay': 1e-4\n",
    "       }\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "args['device'] = device\n",
    "\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae002680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
