{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c4d1ea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "from skimage import io, transform\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aec12ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Add': ['./Dataset/c23/original\\\\0\\\\16.jpg', './Dataset/c23/original\\\\0\\\\16.jpg', './Dataset/c23/original\\\\0\\\\16.jpg', './Dataset/c23\\\\NeuralTextures\\\\0\\\\16.jpg']}\n",
      "{'Add': ['./Dataset/c23/original\\\\0\\\\23.jpg', './Dataset/c23/original\\\\0\\\\23.jpg', './Dataset/c23/original\\\\0\\\\23.jpg', './Dataset/c23\\\\NeuralTextures\\\\0\\\\23.jpg', './Dataset/c23/original\\\\0\\\\16.jpg', './Dataset/c23/original\\\\0\\\\16.jpg', './Dataset/c23/original\\\\0\\\\16.jpg', './Dataset/c23\\\\NeuralTextures\\\\0\\\\16.jpg']}\n",
      "{'Add': ['./Dataset/c23/original\\\\0\\\\23.jpg', './Dataset/c23/original\\\\0\\\\23.jpg', './Dataset/c23/original\\\\0\\\\23.jpg', './Dataset/c23\\\\NeuralTextures\\\\0\\\\23.jpg', './Dataset/c23/original\\\\0\\\\3.jpg', './Dataset/c23/original\\\\0\\\\3.jpg', './Dataset/c23/original\\\\0\\\\3.jpg', './Dataset/c23\\\\Face2Face\\\\0\\\\3.jpg', './Dataset/c23/original\\\\0\\\\16.jpg', './Dataset/c23/original\\\\0\\\\16.jpg', './Dataset/c23/original\\\\0\\\\16.jpg', './Dataset/c23\\\\NeuralTextures\\\\0\\\\16.jpg']}\n"
     ]
    }
   ],
   "source": [
    "fake_add = './Dataset/c23'\n",
    "origin_add = './Dataset/c23/original'\n",
    "forg_types = ['Deepfakes','Face2Face','FaceSwap','NeuralTextures']\n",
    "add_csv = {'Add':[]}\n",
    "for fold in os.listdir(origin_add):\n",
    "    rnd_idx = random.sample(list(range(0,30)),3)\n",
    "    for rnd in rnd_idx:\n",
    "        add = os.path.join(origin_add, fold, str(rnd)+'.jpg')\n",
    "        pic_adds = [add]*3\n",
    "        forge = random.sample(forg_types, 1)[0]\n",
    "        pic_adds.append(os.path.join(fake_add,forge,fold, str(rnd)+'.jpg'))\n",
    "        imp_idx = random.sample(list(range(0,len(add_csv['Add'])+1 , 4)),1)[0]\n",
    "        add_csv['Add'][imp_idx:imp_idx] = pic_adds\n",
    "        print(add_csv)\n",
    "        df = pd.DataFrame(add_csv)\n",
    "        df.to_csv('train_add.csv', index = True)\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ad37d047",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceForensic():\n",
    "    \"\"\"Face Forensic Dataset.\"\"\"\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.face_add = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.face_add)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_add = self.face_add.iloc[idx, 1]\n",
    "        image = Image.open(img_add)\n",
    "        if self.transform:\n",
    "            if idx % 4 in [0,3]: \n",
    "                image = self.transform['transform1'](image)\n",
    "            elif idx % 4 == 1:\n",
    "                image = self.transform['transform2'](image)\n",
    "            else:\n",
    "                image = self.transform['transform3'](image)\n",
    "\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fb4bcc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform1 = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor(),\n",
    "                                  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "transform2 = transforms.Compose([transforms.RandomVerticalFlip(p=1),transforms.Resize((224,224)),transforms.ToTensor(),\n",
    "                  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "trasnform3 = transforms.Compose([transforms.RandomHorizontalFlip(p=1),transforms.Resize((224,224)),transforms.ToTensor(),\n",
    "                  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "trfms = {'transform1': transform1 ,'transform2': transform2, 'transform3': trasnform3 }\n",
    "forensic_dataset = FaceForensic('train_add.csv', trfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2636d709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(forensic_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "24fd168a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.9064,  1.9064,  1.9064,  ...,  0.7248,  0.1939, -0.0287],\n",
       "         [ 1.9064,  1.9064,  1.8893,  ...,  0.6221,  0.1768, -0.0116],\n",
       "         [ 1.8893,  1.8893,  1.8722,  ...,  0.4508,  0.1597,  0.0398],\n",
       "         ...,\n",
       "         [ 1.8037,  1.7865,  1.7523,  ...,  1.4269,  1.4440,  1.4612],\n",
       "         [ 1.7865,  1.7865,  1.7694,  ...,  1.4954,  1.5125,  1.5297],\n",
       "         [ 1.7865,  1.7865,  1.7694,  ...,  1.5468,  1.5639,  1.5810]],\n",
       "\n",
       "        [[ 2.0434,  2.0434,  2.0434,  ...,  0.6429,  0.1176, -0.1099],\n",
       "         [ 2.0434,  2.0434,  2.0434,  ...,  0.5203,  0.0826, -0.0924],\n",
       "         [ 2.0609,  2.0609,  2.0434,  ...,  0.3277,  0.0301, -0.0749],\n",
       "         ...,\n",
       "         [ 1.9209,  1.9034,  1.8683,  ...,  1.5357,  1.5532,  1.5707],\n",
       "         [ 1.9034,  1.9034,  1.8859,  ...,  1.6057,  1.6232,  1.6408],\n",
       "         [ 1.9034,  1.9034,  1.8859,  ...,  1.6583,  1.6758,  1.6933]],\n",
       "\n",
       "        [[ 2.2740,  2.2740,  2.2740,  ...,  0.8797,  0.3568,  0.1476],\n",
       "         [ 2.2914,  2.2914,  2.2740,  ...,  0.7402,  0.3045,  0.1476],\n",
       "         [ 2.3088,  2.3088,  2.2914,  ...,  0.5136,  0.2348,  0.1302],\n",
       "         ...,\n",
       "         [ 2.3263,  2.3088,  2.2740,  ...,  1.8731,  1.8905,  1.9080],\n",
       "         [ 2.3088,  2.3088,  2.2914,  ...,  1.9428,  1.9603,  1.9777],\n",
       "         [ 2.3088,  2.3088,  2.2914,  ...,  1.9951,  2.0125,  2.0300]]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forensic_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9e3a98ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(forensic_dataset, batch_size=4,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "bb8148c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([4, 3, 224, 224])\n",
      "1\n",
      "torch.Size([4, 3, 224, 224])\n",
      "2\n",
      "torch.Size([4, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for i_batch, images_batch in enumerate(dataloader):\n",
    "    print(i_batch)\n",
    "    print(images_batch.size())\n",
    "    #grid = utils.make_grid(images_batch)\n",
    "    #plt.imshow(grid.numpy().transpose((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d39f36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e5a891f349e85f1bddd1318824d5ad5dd82a6576299774c2e8bdc98971d8e1d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
